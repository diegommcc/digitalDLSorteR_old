% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/dnnModel.R
\name{trainDigitalDLSorterModel}
\alias{trainDigitalDLSorterModel}
\title{Train \code{DigitalDLSorter} Deep Neural Network model.}
\usage{
trainDigitalDLSorterModel(
  object,
  batch.size = 128,
  num.epochs = 20,
  val = FALSE,
  freq.val = 0.1,
  loss = "kullback_leibler_divergence",
  metrics = c("accuracy", "mean_absolute_error", "categorical_accuracy"),
  view.metrics.plot = TRUE,
  verbose = TRUE
)
}
\arguments{
\item{object}{\code{\link{DigitalDLSorter}} object with \code{final.data}
slot.}

\item{batch.size}{Number of samples per gradient update. If unspecified,
\code{batch.size} will default to 128.}

\item{num.epochs}{Number of epochs to train the model.}

\item{val}{Boolean that determines if a validation subset is used during
training (\code{FALSE} by default).}

\item{freq.val}{Number between 0.1 and 0.5 that determines the number of
samples from training data that will be used as validation subset.}

\item{loss}{Character indicating loss function selected for training the
model (Kullback-Leibler divergence by default). Look at keras documentation
to see available loss functions.}

\item{metrics}{Vector of metrics used to evaluate the performance of the
model during training and on test data (\code{c("accuracy",
"mean_absolute_error", "categorical_accuracy")} by default)}

\item{verbose}{Boolean indicating if show the progression of the model during
training. Besides, it is shown information about the architecture of the
model (\code{TRUE} by default).}

\item{view.metrics.plots}{Boolean indicating if show progression plots of
loss and metrics during training (\code{TRUE} by default). \code{keras} for
R allows to see the progression of the model during training if you are
working on RStudio.}
}
\value{
A \code{\link{DigitalDLSorter}} object with \code{trained.model} slot
  containing a \code{\link{DigitalDLSorterDNN}} object. For more information
  about the structure of this class, see \code{\link{?DigitalDLSorterDNN}}.
}
\description{
Train \code{\link{DigitalDLSorter}} Deep Neural Network model with data store
in \code{final.data} slot. Moreover, model is evaluated on test data and
prediction results are produced.
}
\details{
All steps related with Deep Neural Network in \code{digitalDLSorteR} package
are performed by using \code{keras} package, an API in R for \code{keras} in
Python available from CRAN. We recommend use the guide of installation
available on \url{https://keras.rstudio.com/} in order to set a custom
configuration (type of back-end used, CPU or GPU, etc.).

Although \code{trainDigitalDLSorterModel} allows to select a custom loss
function used during training, we recommend using Kullback-Leibler divergence
because its better results. If you want to know more details about the
architecture of the DNN and its construction, see Torroja and Sanchez-Cabo,
2019.
}
\examples{
\dontrun{
DDLSChung <- trainDigitalDLSorterModel(
  object = DDLSChung,
  batch.size = 128,
  num.epochs = 20
)
}

}
\references{
Torroja, C. y SÃ¡nchez-Cabo, F. (2019). digitalDLSorter: A Deep
Learning algorithm to quantify immune cell populations based on scRNA-Seq
data. Frontiers in Genetics 10, 978. doi: \url{10.3389/fgene.2019.00978}
}
\seealso{
\code{\link{plotTrainingHistory}}
  \code{\link{deconvDigitalDLSorterModel}}
}
