% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/simBulk.R
\name{prepareDataForTraining}
\alias{prepareDataForTraining}
\title{Generate training and test final data for training DNN model.}
\usage{
prepareDataForTraining(
  object,
  type.data,
  combine = TRUE,
  file.backend = NULL,
  verbose = TRUE
)
}
\arguments{
\item{object}{\code{DigitalDLSorter} object with \code{single.cell.sim} and
\code{prob.cell.types} slots.}

\item{type.data}{Type of data to generate among 'train', 'test' or 'both'
(the last by default).}

\item{file.backend}{Valid file path where to save the HDF5 file used as backend.
If it is equal to \code{NULL} (by default), the data are produced and loaded in memory.}

\item{verbose}{Show messages during the execution.}
}
\value{
A DigitalDLSorter object with \code{final.data} slot containing
a list with one or two entries (depending on selected \code{type.data} argument):
'train' and 'test'. Each entry contains a \code{SummarizedExperiment} object
with single-cell and bulk samples combined in \code{assay} slot, sample names in
\code{rowData} slot and feature names in \code{colData} slot.
}
\description{
Generate training and test final data for training Deep Neural Network model.
To do this, first single-cell and bulk profiles are combined into a single
expression matrix. Then, counts per million (CPM) in log2-space are computed and
normalized. Finally, all samples are shuffled in order to avoid biases
during training. Note that expression matrix is transposed in order to prepare
data for training.
}
\details{
\code{digitalDLSorteR} allows the use of HDF5 files as backend for the resulting data
using \code{DelayedArray} and \code{HDF5Array} frameworks in cases of generating
too large expression matrix to work with it loaded in memory. You need to provide
a valid file path to store the resulting file with '.h5' extension. The data
will be accessible from R without being loaded into memory. This option
slightly slows down execution times, since subsequent transformations of data
will be carried out by chunks instead of using all data. We
recommend this options due to the large size of the simulated matrices.
}
\examples{
## loading all data in memory
DDLSChung <- prepareDataForTraining(
  object = DDLSChung,
  type.data = "both",
  verbose = TRUE
)

## using HDF5 as backend
DDLSChung <- prepareDataForTraining(
  object = DDLSChung,
  type.data = "both",
  file.backend = "DDLSChung.final.data.combined.h5",
  verbose = TRUE
)

}
\seealso{
\code{\link{generateBulkSamples}},
\code{\link{generateTrainAndTestProbMatrix}}.
}
