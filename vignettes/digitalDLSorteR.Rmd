---
title: "digitalLDSorteR: R package for deconvolution of bulk RNA-Seq samples based on Deep Learning"
author:
  - name: First Author
    affiliation: First Author's Affiliation
  - name: Second Author
    affiliation: Second Author's Affiliation
    email: corresponding@author.com
package: digitalDLSorteR
output: 
  BiocStyle::html_document:
    toc: true
    toc_float: true
    css: "style.css"
  BiocStyle::pdf_document:
    toc: true
    toc_float: true
classoption: a4paper
geometry: margin=3cm
fontsize: 12pt
abstract: |
  Introduction of main functionalities of digitalDLSorteR. This package has 
  two goals. First, to offer a set of pre-trained deconvolution models for 
  the prediction of cell composition in bulk RNA-seq samples quickly and easily. 
  Second, digitalDLSorteR provides all the necessary functions for the 
  construction of new deconvolution models from scRNA-seq data. In this 
  vignette, both ways of use are explained using data loaded into the package. 
vignette: |
  %\VignetteIndexEntry{digitalLDSorteR: R package for deconvolution of bulk RNA-Seq samples based on Deep Learning}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
  %\VignettePackage{digitalDLSorteR}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, collapse = TRUE)
options(width = 70)
require(BiocStyle)
```


# Introduction to _digitalDLSorteR_ package

_digitalDLSorteR_ is an R package that implements a Deep Learning based method to 
enumerate and quantify the cell type composition of bulk RNA-Seq samples. Our 
method makes use of Deep Neural Network (DNN) models to adjust any cell type
composition starting from single-cell RNA-Seq (scRNA-Seq) data. 

The rationale of the method consists in a process that starts from scRNA-Seq 
data and, after a few steps, a Deep Neural Network (DNN) model is trained with 
simulated bulk RNA-seq 
samples whose cell composition is known. The trained model is able to 
deconvolve any bulk RNA-seq sample by determining the proportion of the 
different cell types present in it. The main advantage of this method is the
possibility of building deconvolution models trained with real data which comes
from certain biological environments. For example, for quantifying the proportion
of tumor infiltrated lymphocytes (TILs) in breast cancer, 
by following this protocol you can obtain a specific model
for this type of samples. This fact overcomes the limitation of other methods,
since stromal and immune cells change significantly their profiles depending on
the tissue and disease context. 

The package can be used in two ways: for deconvolving bulk RNA-seq
samples using a pre-trained model provided by us or for building your own models
trained from your own scRNA-seq samples. These 
new models may be published in order to make them available for other users
that work with similar data (e.g. neural environment, prostate cancer environment,
etc.). For the moment, the available models allows the deconvolution of TILs 
from breast cancer classified by our team. 

# Installation

_digitalDLSorteR_ only has been tested on Linux, so, for the moment, we 
recomend its installation only on Linux distributions. This is a development 
version, so only it is possible its installation from GitHub by `devtools`.

```{r eval=FALSE}
if (!requireNamespace("devtools", quietly = TRUE))
    install.packages("devtools")
devtools::install_github("diegommcc/digitalDLSorteR")
```

_digitalDLSorteR_ is based on DNN models. To do this, it uses
[Keras](https://cloud.r-project.org/web/packages/keras/index.html) 
package available from CRAN, a high-level neural networks API implemented on 
Python. Keras R version works as interface between these two languages by using 
[reticulate](https://cran.r-project.org/web/packages/reticulate/index.html) 
package, so, during the installation, Keras requires that you provdes a Python 
interpreter for working. We recommend the use of conda environments to 
provide a Python interpreter with all dependencies covered. If you have a 
conda environment compatible with Keras requirements, the package will find it 
automatically. If not, Keras package will create a new environment named 
`r-reticulate` There are other methods for installing a functionally back-end, 
see <https://keras.rstudio.com/reference/install_keras.html> for more details.

```{r eval=FALSE}
install.packages("keras")
library(keras)
install_keras(method = "conda") # other options are available
```

This is the default CPU-based installation, but it is possible a 
more customized installation. 
See <https://tensorflow.rstudio.com/installation/> and
<https://keras.rstudio.com/reference/install_keras.html>.


# Using pre-trained models for deconvolving bulk RNA-seq samples

This is the simplest way to use the method. Only it is necessary a bulk RNA-seq
sample matrix with genes as rows (in symbol notation) and samples as columns and
the package returns the predicted cell composition of each sample. As mentioned
above, for the moment, only one model for deconvolving breast cancer samples is
available. This model was generated from GSE75688 (Chung et al., 2017) data set
whose cells were characterized by our team. It is oriented to the quantification
of immune cell types in cancer samples. This presents advantages over other tools,
since it has been trained from scRNA-Seq data from the tumor itself, preserving
the specific characteristics of the tumor microenvironment as opposite to other
approaches in which cells were isolated from blood. Moreover, we have 
provided two resolution levels for the deconvolution task:

* First, a model trained with cell types characterized at high resolution level:
ER+, HER2+, ER+/HER2+, TNBC, stromal, monocyte, TCD4mem (memory CD4+ T cell), 
BGC (germinal center B cell), Bmem (memory B cell), DC (dendritic cell),
macrophage, TCD8 (CD8+ T cell) and TCD4reg (regulatory CD4+ T cell). Note that 
intrinsic subtypes of breast cancer are taken into account independently.

* Second, a model trained with cell types less specific: B cells, T CD4+ cells,
T CD8+ cells, monocytes, dendritic cells, stromal cells and tumor cells. Each one
is a more general group which includes the above cell types.

For more information about the data set, see the provided documentation in the
package. 

## Package usage example

Using the package in this way, it is only necessary to load the samples that you
want to deconvolve in R and use them as `data` argument for 
`deconvDigitalDLSorter` function. This object must be a `matrix` or a `data.frame`
with genes as rows and samples as columns. Genes must be annotated as SYMBOL, 
since the model was trained with this notation. Data must be TPMs, since model
was trained with this type of data. If data is not normalized, set `normalize`
argument equal to `TRUE` (by default). Moreover, you must specify the model that 
will be used in `model` argument. In this example, we are going to deconvolve a 
small subset of TCGA samples from breast sample. We are using the generic version 
(`model = "breast.chung.generic"`), but it is also possible the use of specific 
(`model = "breast.chung.specific"`):

```{r deconvolvingTCGA, message=FALSE}
library(digitalDLSorteR)

# this line is to ensure compatibility with all machines
tensorflow::tf$compat$v1$disable_eager_execution()

deconvResults <- deconvDigitalDLSorter(
  data = TCGA.breast.small,
  model = "breast.chung.generic",
  normalize = TRUE
)

head(deconvResults)
```

`deconvDigitalDLSorter` returns a data frame with the provided samples ($k$) in 
rows and cell types considered by the model ($j$) in columns. Each entry 
corresponds with the proportion of $k$ cell type in $i$ sample. In order to 
evaluate the results quickly by a bar plot, you can use `barplotCellTypes` function as follows:

```{r resultsDeconvTCGA}
barPlotCellTypes(
  deconvResults, 
  rm.x.text = TRUE,
  color.line = "black",
  title = "Results of deconvolution of TCGA breast samples"
)
```

# Build your own model from scRNA-seq data

_digitalDLSorteR_ allows to train new models from different scRNA-Seq data 
in order to offer the possibility to generate models more suitable for 
determined biological environments. For this, the steps described in the 
following pipeline must be followed. As example, we are going to generate a 
'toy' model from scRNA-seq data used for building the `breast.chung` model 
available in the package. You must bear in mind that both the original data 
and the parameters used do not allow obtaining an accurate model in order to 
reduce execution times.

## Load data into a `DigitalDLSorter` object

First, we have to load data into a `DigitalDLSorter` object, the core of the 
package. This S4 class contains all slots necessaries for storing the different 
data generated during the building of the model. The 
information that you must provide consists in three elements: 

* Single-cell counts: a matrix with genes in rows and cells in columns. Both must 
present the corresponding row and column names.
* Cells metadata: a table with annotations (columns) for each cell (rows). The 
information expected in this element are metadata that could be used as 
covariates in the next steps (gender, type of sample...), one column with the 
ID used for each cell and one column with the corresponding cell types.
* Genes metadata with annotations (columns) for each gene (rows). In the same 
way that in cells metadata, the information that is expected in this element 
are a column with the notation used for each gene in counts matrix and others 
covariates like gene length, GC content, etc. You can inspect 
`single.cell.real(DDLSChungSmall)` object in order to 
understand the required structure if you use a `SingleCellExperiment` object as 
input.

**Note:** Data used for the examples are stored into the package as a 
`SingleCellExperiment` object. This object contains the results of different 
steps in order to avoid some steps whose execution is extensive, specifically 
the estimation of new scRNA-seq profiles.

If your data contains a low number of cells or some cell types are poorly 
represented, you must load data with `loadRealSCProfiles` function. Data is loaded
into `single.cell.real` slot for estimating parameters in order to simulate new 
single-cell profiles (see the following steps). If your data does not present 
this features and it is not necessary the simulation of new single-cell profiles, 
you can use `loadFinalSCProfiles`, that loads data into `single.cell.final` slot. 
In this vignette, we are going to present the large protocol.

```{r loadData, eval=FALSE}
## this code will not be run
DDLSChungSmall <- loadRealSCProfiles(
  single.cell.real = sc.chung.breast, # SingleCellExperiment object
  cell.ID.column = "Cell_ID",
  gene.ID.column = "external_gene_name",
  min.cells = 0,
  min.counts = 0,
  project = "Chung_etal_2017"
)
```
In this case, we are loading single-cell profiles from a `SingleCellExperiment` 
object, but it is also possible to load it from tsv files and sparse matrices. 
The code would be as follows:

```{r loadFromFile, eval=FALSE}
## this code will not be run
filesChung <- c("countsMatrix.tsv.gz", 
                "cellsMetadata.tsv.gz",
                "genesMetadata.tsv.gz")

DDLSChung <- loadRealSCProfiles(
  single.cell.real = filesChung,
  cell.ID.column = "Cell_ID",
  gene.ID.column = "external_gene_name",
  min.cells = 0,
  min.counts = 0,
  project = "Chung_etal_2017"
)
```

## Estimation of parameters of ZINB-WaVE model for simulating new single-cell 
profiles

If data is loaded into `single.cell.real` slot, new simulated single-cell profiles
based on real profiles will be generated. The goal is the oversampling of low
frequency cell types in order to increase their signal and 
train the model in a balanced way. For this purpose, _digitalDLSorteR_ uses the
ZINB-WaVE framework () to estimate the parameters of a ZINB (zero-inflated 
negative binomial) distribution to simulate new single-cell profiles. This 
model was chosen due to its ability to accommodate not only the variability 
within a particular cell type but also the variability within the whole 
experiment. 

The process is performed by `estimateZinbwaveParams` function. It implements 
the ZINB-WaVE model by using `r Biocpkg("splatter")` package, a wrapper of 
`r Biocpkg("zinbwave")` package. You must specify the column 
that corresponds with cell types in cells metadata. Moreover, you can add cell 
covariates based 
on your experimental design such as patient or gender and gene covariates such 
as gene length. This process may take a few minutes to run because it 
is poorly optimized in the original packages, so be patient. For this vignette, 
ZINB-WaVE model is pre-loaded from _digitalDLSorteR_ package in order to avoid the 
wait. In any case, you can adjust the number of threads to use in some steps 
during the estimation with `threads` argument. `r Biocpkg("BiocParallel")` 
package is used for this proposal.
 

```{r zinbwaveEstimation, eval=FALSE}
## this code will not be run
DDLSChungSmall <- estimateZinbwaveParams(
  object = DDLSChungSmall,
  cell.ID.column = "Cell_ID",
  gene.ID.column = "external_gene_name",
  cell.type.column = "Cell_type",
  cell.cov.columns = "Patient",
  gene.cov.columns = "gene_length",
  threads = 4,
  verbose = TRUE
)
```

The resulting model is stored in `zinb.params` slot. You can access with its 
getter function or show the content of `DigitalDLSorter` object:

```{r}
DDLSChungSmall
```

## Simulate new single-cell profiles using the estimated parameters

Once ZINB-WaVE parameters are estimated, `simSingleCellProfiles` function uses 
them for simulating new single-cell profiles based on real single-cell profiles. 
The simulation is performed by randomly sampling from a negative binomial 
distribution with ZINB parameters estimated ($\mu$ and $\theta$) and introducing 
dropouts by sampling from a binomial distribution with estimated $\pi$ 
probability. You must specify the number of cell profiles per cell type that 
will be generated. For example, if your data set is composed by 10 cell types and 
`n.cells` is equal to 10, the number of simulated profiles will be 100. 

```{r}
DDLSChungSmall <- simSingleCellProfiles(
  object = DDLSChungSmall,
  cell.ID.column = "Cell_ID",
  cell.type.column = "Cell_type",
  n.cells = 10,
  verbose = TRUE
)
```

The resulting simulated data is stored in `single.cell.final` slot to be used
for the simulation of bulk RNA-seq profiles with known cell composition.


## Generate cell composition matrix for bulk simulated expression profiles

For simulating bulk samples, first, it is necessary the generation of a cell 
composition matrix which determines the proportion of each cell type in each 
sample. It is carried out by `generateTrainAndTestBulkProbMatrix` function and 
the results are stored in `prob.cell.types` slot as a `ProbMatrixCellTypes` object. 

For this process, first, single-cell profiles are split in train and test 
data (see `train.freq`). This is because each subset of single-cell data will 
form each subset of bulk samples, avoiding the distortion of results. Then, 
proportions are generated by five different methods in order to avoid biases 
during training due to the cell composition of simulated bulk NRA-seq samples:

1. Cell proportions are randomly sampled from a truncated uniform distribution
with predefined limits according to _a priori_ knowledge of the abundance 
of each cell type (see `prob.design` argument). This information ban be
inferred from the single cell analysis itself or from the literature.
2. A second set is generated by randomly permuting cell type labels from a
distribution generated by the previous method.
3. Cell proportions are randomly sampled as by method 1 without replacement.
4. Using the last method for generating proportions, cell types labels are 
randomly sampled.
5. Cell proportions are randomly sampled from a Dirichlet distribution.

The limits of each cell type according to _a priori_ knowledge 
are defined by a `data.frame` with the structure of `probMatrix` object in the 
following code. This information can be estimated from the single-cell 
experiment itself or from literature. You can specify the number of bulk 
samples that will be simulated with
`num.bulk.samples` argument (by default, approximately 18 more samples will be 
formed than there are cells in `single.cell.final` slot) and the proportion of 
bulk samples that will be generated by each method 
in train and test data with `proportions.train` and `proportions.test` arguments. 
By default, 85% of samples are generated by the methods that introduce the greatest 
randomness in the proportions (methods 2, 3, 4 and 5). The remaining samples are 
generated by the first method. 

```{r}
probMatrix <- data.frame(
  Cell_type = c("ER+", "HER2+", "ER+ and HER2+", "TNBC",
                 "Stromal", "Monocyte", "Tme", "BGC",
                 "Bmem", "DC", "Macrophage", "TCD8", "Treg"),
  from = c(rep(30, 4), 1, rep(0, 8)),
  to = c(rep(70, 4), 50, rep(15, 8))
)

DDLSChungSmall <- generateTrainAndTestBulkProbMatrix(
  object = DDLSChungSmall,
  cell.type.column = "Cell_type",
  prob.design = probMatrix,
  num.bulk.samples = 200,
  verbose = TRUE
)
```

In this example, we are simulating the proportions of 200 bulk samples for 
avoid an excessive use of RAM in the following steps. In real circumstances, 
we recommend, depending on the number of starting
single-cell profiles and the available computational resources, about 30000 
samples and the default proportions. 

You can investigate the cell composition matrix created in this step:

```{r}
head(getProbMatrix(DDLSChungSmall, type.data = "train"))
tail(getProbMatrix(DDLSChungSmall, type.data = "train"))
```

However, it is more suitable to know full distribution of proportions 
generated by each method using 
`showProbPlot` function. This function show different ways for visualizing this
information. In the following code, we are going to display the former and the 
last distributions of train samples:

```{r showPrbPlot}
lapply(c(1, 6), function(x) {
  showProbPlot(DDLSChungSmall,
               type.data = "train", set = x, type.plot = "boxplot")
})
```

Probably, distributions presents different medians between cell types or 
similar things. This is because of the low number of samples that are being 
simulated. 


## Simulate bulk RNA-seq profiles with known cell composition

As in tissues the expression levels of each gene from a bulk RNA-seq experiment 
represent the summation of different cells, _digitalDLSorteR_ simulates new 
profiles by adding the expression levels of each gene from single-cell profiles 
according to the proportions generated in the previous step. Therefore, the 
bulk matrix expression will be simulated according the Equation \#eq:bulk:


\begin{equation}
  T_{ij} = \sum_{k = 1}^{K} \sum_{z = 1}^Z C_{izk} 
  (\#eq:bulk)
\end{equation}

\begin{equation*}
  \textrm{such as} \left\{
\begin{array}{l}
  i = 1 \ldots M;\\
  j = 1 \ldots N \\
  Z = 1 \ldots 100 \cdot P_{kj} \\
  \sum_{k = 1}^K Z \cdot P_{kj} = 100
\end{array}
\right.  
\end{equation*}

where $T_{ij}$ is the expression level of $i$ gene in $j$ bulk sample; $C_{izk}$
is the expression level of $i$ gene in $z$ cell in $j$ bulk sample; and 
$P_{kj}$ is the proportion of $k$ cell type in $j$ bulk sample (the cell 
composition matrix generated in the preious step). $Z$ represents the number of 
cells that will compound the proportion of $k$ cell type in $j$ bulk sample. 
These cells are randomly sampled based on their cell type. Finally, each bulk 
sample will be form by 100 cells. 

This step is carried out by `generateBulkSamples` function as shown in the 
following code box:

```{r generateBulkSamples}
DDLSChungSmall <- generateBulkSamples(
  DDLSChungSmall,
  type.data = "both"
)
```

You can see the show message from the object in order to know information
about the steps done.

```{r showMessage}
DDLSChungSmall
```

This way of use will load all bulk samples in-memory. If the number of bulk 
samples increases, It is possible to use HDF5 files as a back-end for storing 
data through packages `r Biocpkg("DelayedArray")` and `r Biocpkg("HDF5Array")`. 
These packages allows to store data on-disk while this data is accessible from R 
session dynamically. You will simulate large amounts of bulk samples in order 
to obtain a better deconvolution model. The use is the same as above but 
providing in `file.backend` argument a valid path to store HDF5 file. 
 
```{r eval=FALSE}
## this code will not be run
DDLSChung <- generateBulkSamples(
  DDLSChung,
  type.data = "both",
  file.backend = file.path(validFilePath, "bulk_simul_samples.h5")
)
```

We recommend this way of use because the training of deep neural network can be 
computationally heavy in terms of memory used. 


## Prepare data for training and evaluating the Deep Neural Network model

The next step consists in the preparation of data for training the Deep Neural 
Network model. You can specify which type of data will be used for training 
the model: only single-cell profiles, only bulk profiles or a combination of both. 
We recommend using bulk profiles or a combination, since the neural network works
better if samples consists in a combination of cell types with different 
proportions. In this way, the model is able to find patterns in the expression 
profiles that define each cell type.

Then, selected data is normalized (by computing CPMs and classic normalization), 
shuffled and transposed for its use as input in the neural network. It should 
be noted that, as in the previous step, it is possible to use HDF5Array files 
as back-end to store the samples that will be used for training.

```{r prepareDataForTraining}
DDLSChungSmall <- prepareDataForTraining(
  object = DDLSChungSmall,
  type.data = "both",
  combine = "both",
  verbose = TRUE
)
```

## Train and evaluate digitalDLSorter model

With data stored in `final.data` slot, Deep Neural Network will be trained 
and evaluated. This step is performed by `trainDigitalDLSorterModel` function and
uses `r CRANpkg("keras")` framework for all steps related with Deep Learning. 
`r CRANpkg("keras")` package is an interface to keras module from Python for 
high level Deep Learning. If you want to know more information about architecture
and hyperparameters of the Deep Neural Network implemented in _digitalDLSorteR_, 
see Torroja and Sanchez-Cabo, 2019. 

The use is very simple, only is needed the specification of the number of epochs 
and the batch size used. In this example, we are going to use 5 epochs in order to 
reduce execution times, but for a good training, you should test different 
values. With 20 epochs should be enough. Moreover, you can specify the 
loss function and the metrics used during training. We are groin to use all default
parameters: Kullback-Leibler divergence as loss function and 
accuracy and mean absolute error as metrics. In the following versions, the 
possibility of contributing Keras models with different architecture through 
arguments will be implemented.


```{r trainDNN}
DDLSChungSmall <- trainDigitalDLSorterModel(
  object = DDLSChungSmall,
  num.epochs = 5,
  view.metrics.plot = FALSE
)
```

After that, `DDLSChung` contains in `trained.model` slot a `DigitalDLSorterDNN` object
with all the information relative to the model: trained keras model, history 
of metrics during training, prediction results on test data and resulting metrics 
from prediction over test data. 

Obviously, this is only an example and metrics are horrible in general, since the
number of samples and the number of epochs are very low. 


## Evaluation of trained model

In spite of training metrics and resulting metrics from predict on test data 
are informative about the performance of the model, a more exhaustive analysis 
of the performance model on test data is important to do. For this task, 
_digitalDLSorteR_ offers a set of visualization functions for representing varied 
error metrics in different ways.

First, we have to use `calculateErrorMetrics` in order to obtain the error metrics
that will be represented. By default, absolute error (AbsErr),
proportional absolute error (ppAbsErr), squared error (SqrErr) and
proportional squared error (ppSqrErr) are calculated for each sample from test 
data. Moreover, each one of these metrics are aggregated using their average 
values by three criteria: each cell type (`CellType`), probability bins of 0.1 
(`pBin`), number of differen cell types present in the samples (`nMix`) and a 
combination of `pBin` and `nMix` (`pBinMix`). Finally, all computation are 
repeated only for bulk samples, removing single-cell profiles 
from the evaluation.

```{r calculateEval}
DDLSChungSmall <- calculateEvalMetrics(DDLSChungSmall)
```

The results are stored in `eval.stats.samples` slot of `DigitalDLSorterDNN` 
object. Then, we can represent error metrics with the following functions. 


### Distribution of errors by different variables

`distErrorPlot` function allows to represent the distribution of errors by 
different ways. Moreover, it allows to split charts in different panels 
representing how errors are distributed by a determined variable. The variables
available are cell types (`CellType`) and number of cell types present in samples
(`nMix`). In the following example, we are going to represent the overall 
erros by cell types. 

```{r distErr1}
distErrorPlot(
  DDLSChungSmall,
  error = "AbsErr",
  x.by = "CellType",
  color.by = "CellType", 
  error.labels = FALSE, 
  type = "boxplot",
  size.point = 1
)
```

Now, if you want to know if there are some bias in direction to a specific cell type
in determined proportions, you can use the next code:

```{r distErr2}
distErrorPlot(
  DDLSChungSmall,
  error = "AbsErr",
  facet.by = "CellType",
  color.by = "nMix", 
  error.labels = TRUE, 
  type = "violinplot",
  size.point = 1
)
```

It is also possible to represent errors by number of different cell types present
in samples: 

```{r distErr3}
distErrorPlot(
  DDLSChungSmall,
  error = "AbsErr",
  color.by = "CellType", 
  facet.by = "nMix",
  type = "boxplot",
  size.point = 1
)
```

Finally, with `barErrorPlot` you can represent the mean error values with their
corresponding dispersion ranges as follows:

```{r barError}
barErrorPlot(DDLSChungSmall, error = "MAE", by = "CellType")
```



### Correlation plots between predicted and expected proportions

Ideally, the model should provide predictions that fit linearly to the 
real proportions. Thus, you can generate correlations plots in order to 
evaluate how well the predictions fit the actual proportions. By default, 
Pearson's coefficient correlation ($R$) and concordance correlation coefficient
(CCC) are shown as annotations in plots. The latter is a more realistic measure 
of the situation, as it decreases as the points move away from the perfect
diagonal.


```{r corr1}
corrExpPredPlot(
  DDLSChungSmall,
  color.by = "CellType",
  size.point = 1,
  corr = "both"
)
```

As in the previous case, charts can be divided according to different variables. 
Now, we are going to split results by `CellType` and by `nMix`:

```{r corr2}
corrExpPredPlot(
  DDLSChungSmall,
  color.by = "CellType",
  facet.by = "CellType",
  size.point = 1, 
  filter.sc = F,
  corr = "both"
)
```

```{r corr3}
corrExpPredPlot(
  DDLSChungSmall,
  color.by = "CellType",
  facet.by = "nMix",
  size.point = 1,
  corr = "both"
)
```

### Bland-Altman agreement plots

`blandAltmanLehPlot` allows to display the Bland-Altman agreement plot. This is
a graphic method to compare the agreement between two different set of values. 
The differences between predictions and real proportions are plotted against 
the averages of the two values. The central dashed line represents the mean different, 
while the two red dashed lines are the limits of agreement, which are defined 
as the mean difference plus and minus 1.96 times the standard deviation of 
the differences. 95% of the differences are expected to fall between these 
two limits. It is also possible the representation in $log_2$ space.

```{r bland1}
blandAltmanLehPlot(
  DDLSChungSmall, 
  color.by = "CellType",
  log.2 = FALSE,
  size.point = 1,
  filter.sc = TRUE,
  density = TRUE,
)
```

Moreover, this function has the same behavior as the previous ones:

```{r bland2}
blandAltmanLehPlot(
  DDLSChungSmall, 
  color.by = "nMix",
  facet.by = "nMix",
  log.2 = FALSE,
  size.point = 1,
  filter.sc = TRUE,
  density = TRUE,
)
```

## Save `DigitalDLSorter` object and trained models

Finally, we have provided different ways to save models on-disk and to recover 
it into the `DigitalDLSorter`. First, you can save `DigitalDLSorter` objects as 
rds and rda file. For rds files, due to this type of files only accepts native 
R objects, they are not able to store complicated data structures as keras 
Python object. In order to make it possible, _digitalDLSorteR_ has a 
`saveRDS` generic function ehich converts keras model object into a list with 
the architecture of the network and the weights after training. These two 
pieces of information are the minimum neccessary to perform new predictions 
with the model. When the model is to be used to make predictions, it is compiled 
back to a keras object. 

```{r saveRDS, eval=FALSE}
## this code will not be run
saveRDS(object = DDLSChungSmall, file = "valid/path")
```

In relation to rda files, since it is possible to store more than one object in 
them, it is necessary to transform the keras model object by the same form that
has been exposed before through `prepareDataForTraining` function. If this step 
is not carried out before saving, trained model will be lost. 

```{r prepareModel, eval=FALSE}
## this code will not be run
DDLSChungSmall <- prepareDataForTraining(DDLSChungSmall)
save(DDLSChungSmall, file = "valid/path")
```

However, the optimizer stage is not saved by these ways. In order to offer 
the possibility of saving the complete model, digitalDLSorteR offers the
functions `saveTrainedModelAsH5` for its saving to disk and `loadTrainedModelFromH5`
for its recovery. Note that only keras model is being saved as HDF5 file by this 
way. 

```{r saveHDF5Model, eval=FALSE}
## this code will not be run
saveTrainedModelAsH5(DDLSChungSmall, file.path = "valid/path")
DDLSChungSmall <- loadTrainedModelFromH5(DDLSChungSmall)
```


# Session info {.unnumbered}

```{r sessionInfo, echo=FALSE}
sessionInfo()
```
